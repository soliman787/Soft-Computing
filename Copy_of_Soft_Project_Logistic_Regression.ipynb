{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx33zKN5laS8pUQKLHjQQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soliman787/Soft-Computing/blob/main/Copy_of_Soft_Project_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "_BityJSKPnso",
        "outputId": "6b15495d-bff3-4579-f97e-c8ec4e6e0c04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             communityName state  countyCode  communityCode  population  \\\n",
              "0  BerkeleyHeightstownship    NJ        39.0         5320.0       11980   \n",
              "1           Marpletownship    PA        45.0        47616.0       23123   \n",
              "2               Tigardcity    OR         NaN            NaN       29344   \n",
              "3         Gloversvillecity    NY        35.0        29443.0       16656   \n",
              "4              Bemidjicity    MN         7.0         5068.0       11245   \n",
              "\n",
              "   householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  ...  \\\n",
              "0           3.10          1.37         91.78          6.50         1.88  ...   \n",
              "1           2.82          0.80         95.57          3.44         0.85  ...   \n",
              "2           2.43          0.74         94.33          3.43         2.35  ...   \n",
              "3           2.40          1.70         97.35          0.50         0.70  ...   \n",
              "4           2.76          0.53         89.16          1.17         0.52  ...   \n",
              "\n",
              "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
              "0        14.0       114.85      138.0     1132.08       16.0           131.26   \n",
              "1        57.0       242.37      376.0     1598.78       26.0           110.55   \n",
              "2       274.0       758.14     1797.0     4972.19      136.0           376.30   \n",
              "3       225.0      1301.78      716.0     4142.56       47.0           271.93   \n",
              "4        91.0       728.93     1060.0     8490.87       91.0           728.93   \n",
              "\n",
              "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
              "0     2.0         16.41                41.02        1394.59  \n",
              "1     1.0          4.25               127.56        1955.95  \n",
              "2    22.0         60.87               218.59        6167.51  \n",
              "3     NaN           NaN               306.64            NaN  \n",
              "4     5.0         40.05                  NaN        9988.79  \n",
              "\n",
              "[5 rows x 146 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63385f60-5531-4a65-9149-d535efd1b345\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>communityName</th>\n",
              "      <th>state</th>\n",
              "      <th>countyCode</th>\n",
              "      <th>communityCode</th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>racepctblack</th>\n",
              "      <th>racePctWhite</th>\n",
              "      <th>racePctAsian</th>\n",
              "      <th>racePctHisp</th>\n",
              "      <th>...</th>\n",
              "      <th>burglaries</th>\n",
              "      <th>burglPerPop</th>\n",
              "      <th>larcenies</th>\n",
              "      <th>larcPerPop</th>\n",
              "      <th>autoTheft</th>\n",
              "      <th>autoTheftPerPop</th>\n",
              "      <th>arsons</th>\n",
              "      <th>arsonsPerPop</th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "      <th>nonViolPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BerkeleyHeightstownship</td>\n",
              "      <td>NJ</td>\n",
              "      <td>39.0</td>\n",
              "      <td>5320.0</td>\n",
              "      <td>11980</td>\n",
              "      <td>3.10</td>\n",
              "      <td>1.37</td>\n",
              "      <td>91.78</td>\n",
              "      <td>6.50</td>\n",
              "      <td>1.88</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>114.85</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1132.08</td>\n",
              "      <td>16.0</td>\n",
              "      <td>131.26</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.41</td>\n",
              "      <td>41.02</td>\n",
              "      <td>1394.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Marpletownship</td>\n",
              "      <td>PA</td>\n",
              "      <td>45.0</td>\n",
              "      <td>47616.0</td>\n",
              "      <td>23123</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.80</td>\n",
              "      <td>95.57</td>\n",
              "      <td>3.44</td>\n",
              "      <td>0.85</td>\n",
              "      <td>...</td>\n",
              "      <td>57.0</td>\n",
              "      <td>242.37</td>\n",
              "      <td>376.0</td>\n",
              "      <td>1598.78</td>\n",
              "      <td>26.0</td>\n",
              "      <td>110.55</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>127.56</td>\n",
              "      <td>1955.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tigardcity</td>\n",
              "      <td>OR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29344</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0.74</td>\n",
              "      <td>94.33</td>\n",
              "      <td>3.43</td>\n",
              "      <td>2.35</td>\n",
              "      <td>...</td>\n",
              "      <td>274.0</td>\n",
              "      <td>758.14</td>\n",
              "      <td>1797.0</td>\n",
              "      <td>4972.19</td>\n",
              "      <td>136.0</td>\n",
              "      <td>376.30</td>\n",
              "      <td>22.0</td>\n",
              "      <td>60.87</td>\n",
              "      <td>218.59</td>\n",
              "      <td>6167.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gloversvillecity</td>\n",
              "      <td>NY</td>\n",
              "      <td>35.0</td>\n",
              "      <td>29443.0</td>\n",
              "      <td>16656</td>\n",
              "      <td>2.40</td>\n",
              "      <td>1.70</td>\n",
              "      <td>97.35</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>...</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1301.78</td>\n",
              "      <td>716.0</td>\n",
              "      <td>4142.56</td>\n",
              "      <td>47.0</td>\n",
              "      <td>271.93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>306.64</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bemidjicity</td>\n",
              "      <td>MN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5068.0</td>\n",
              "      <td>11245</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.53</td>\n",
              "      <td>89.16</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.52</td>\n",
              "      <td>...</td>\n",
              "      <td>91.0</td>\n",
              "      <td>728.93</td>\n",
              "      <td>1060.0</td>\n",
              "      <td>8490.87</td>\n",
              "      <td>91.0</td>\n",
              "      <td>728.93</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9988.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 146 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63385f60-5531-4a65-9149-d535efd1b345')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63385f60-5531-4a65-9149-d535efd1b345 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63385f60-5531-4a65-9149-d535efd1b345');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53c874b2-b904-46d3-8650-ef726ecebe59\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53c874b2-b904-46d3-8650-ef726ecebe59')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53c874b2-b904-46d3-8650-ef726ecebe59 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_raw"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_raw = pd.read_csv('/content/crimedata.csv')\n",
        "\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.info()\n",
        "df_raw.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "oWGIZtA_P_Gq",
        "outputId": "b91896a2-b12b-4244-e4f4-a8b3b5088398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2215 entries, 0 to 2214\n",
            "Columns: 146 entries, communityName to nonViolPerPop\n",
            "dtypes: float64(116), int64(28), object(2)\n",
            "memory usage: 2.5+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "communityName           object\n",
              "state                   object\n",
              "countyCode             float64\n",
              "communityCode          float64\n",
              "population               int64\n",
              "                        ...   \n",
              "autoTheftPerPop        float64\n",
              "arsons                 float64\n",
              "arsonsPerPop           float64\n",
              "ViolentCrimesPerPop    float64\n",
              "nonViolPerPop          float64\n",
              "Length: 146, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>communityName</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>countyCode</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>communityCode</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>autoTheftPerPop</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arsons</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arsonsPerPop</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nonViolPerPop</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n",
        "!pip install pyswarms\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "import pyswarms as ps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZxmb7cmP_I5",
        "outputId": "f6a8d29f-aec5-4e4d-8e37-fe15e4451b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n",
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "print(\"\\n--- Data Preprocessing ---\")\n",
        "\n",
        "\n",
        "if 'ViolentCrimesPerPop' not in df_raw.columns:\n",
        "    print(\"ERROR: 'ViolentCrimesPerPop' column not found. Please check column names.\")\n",
        "\n",
        "    if df_raw.shape[1] > 5:\n",
        "        target_col_name = df_raw.columns[-1]\n",
        "        print(f\"Assuming '{target_col_name}' is the target variable based on position.\")\n",
        "        if df_raw[target_col_name].isnull().all():\n",
        "             print(f\"Target column {target_col_name} is all NaNs. Cannot proceed with it as target.\")\n",
        "\n",
        "             numeric_cols_for_target = df_raw.select_dtypes(include=np.number).columns\n",
        "             if len(numeric_cols_for_target) > 0:\n",
        "                 target_col_name = numeric_cols_for_target[0] # Take the first numeric one\n",
        "                 print(f\"WARNING: Using '{target_col_name}' as a fallback target. THIS IS LIKELY WRONG. Please verify.\")\n",
        "             else:\n",
        "                 print(\"FATAL: No suitable numeric target column found. Please inspect your data.\")\n",
        "                 exit()\n",
        "    else:\n",
        "        print(\"FATAL: Cannot automatically determine target. Please inspect data.\")\n",
        "        exit()\n",
        "else:\n",
        "    target_col_name = 'ViolentCrimesPerPop'\n",
        "\n",
        "df_raw.dropna(subset=[target_col_name], inplace=True)\n",
        "print(f\"Shape after dropping rows with missing target ({target_col_name}): {df_raw.shape}\")\n",
        "\n",
        "if df_raw.empty:\n",
        "    print(f\"FATAL: No data left after dropping NaNs in target column '{target_col_name}'. Check data quality.\")\n",
        "    exit()\n",
        "\n",
        "median_crime = df_raw[target_col_name].median()\n",
        "df_raw['crime_category'] = (df_raw[target_col_name] > median_crime).astype(int)\n",
        "y = df_raw['crime_category']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE8vBfLEP_LO",
        "outputId": "55f5e1ce-73f5-493e-9950-c1bea508e414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Preprocessing ---\n",
            "Shape after dropping rows with missing target (ViolentCrimesPerPop): (1994, 146)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "print(\"\\n--- Data Preprocessing ---\")\n",
        "\n",
        "\n",
        "if 'ViolentCrimesPerPop' not in df_raw.columns:\n",
        "    print(\"ERROR: 'ViolentCrimesPerPop' column not found. Please check column names.\")\n",
        "\n",
        "    if df_raw.shape[1] > 5:\n",
        "        target_col_name = df_raw.columns[-1]\n",
        "        print(f\"Assuming '{target_col_name}' is the target variable based on position.\")\n",
        "        if df_raw[target_col_name].isnull().all():\n",
        "             print(f\"Target column {target_col_name} is all NaNs. Cannot proceed with it as target.\")\n",
        "\n",
        "             numeric_cols_for_target = df_raw.select_dtypes(include=np.number).columns\n",
        "             if len(numeric_cols_for_target) > 0:\n",
        "                 target_col_name = numeric_cols_for_target[0] # Take the first numeric one\n",
        "                 print(f\"WARNING: Using '{target_col_name}' as a fallback target. THIS IS LIKELY WRONG. Please verify.\")\n",
        "             else:\n",
        "                 print(\"FATAL: No suitable numeric target column found. Please inspect your data.\")\n",
        "                 exit()\n",
        "    else:\n",
        "        print(\"FATAL: Cannot automatically determine target. Please inspect data.\")\n",
        "        exit()\n",
        "else:\n",
        "    target_col_name = 'ViolentCrimesPerPop'\n",
        "\n",
        "df_raw.dropna(subset=[target_col_name], inplace=True)\n",
        "print(f\"Shape after dropping rows with missing target ({target_col_name}): {df_raw.shape}\")\n",
        "\n",
        "if df_raw.empty:\n",
        "    print(f\"FATAL: No data left after dropping NaNs in target column '{target_col_name}'. Check data quality.\")\n",
        "    exit()\n",
        "\n",
        "median_crime = df_raw[target_col_name].median()\n",
        "df_raw['crime_category'] = (df_raw[target_col_name] > median_crime).astype(int)\n",
        "y = df_raw['crime_category']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy2EqDgWP_NC",
        "outputId": "77d19b29-9dba-453d-8e24-6b3aebb0dd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Preprocessing ---\n",
            "Shape after dropping rows with missing target (ViolentCrimesPerPop): (1994, 147)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Select features (X) - drop original target, new categorical target, and non-predictive columns\n",
        "\n",
        "cols_to_drop = [target_col_name, 'crime_category', 'communityname', 'state', 'county', 'community', 'fold']\n",
        "cols_to_drop_existing = [col for col in cols_to_drop if col in df_raw.columns]\n",
        "X = df_raw.drop(columns=cols_to_drop_existing)\n",
        "print(f\"Features selected. Shape of X: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZcc5sfpP_PK",
        "outputId": "2fbb341c-f122-454b-dc9a-fb6783b9ced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features selected. Shape of X: (1994, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Handle missing values in features (X) using median imputation\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        try:\n",
        "            X[col] = pd.to_numeric(X[col])\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert column {col} to numeric. It might contain non-numeric strings other than '?'. Dropping it.\")\n",
        "            X.drop(columns=[col], inplace=True)\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
        "\n",
        "print(\"Missing values handled. Shape of X after imputation:\", X.shape)\n",
        "if X.empty or X.shape[1] == 0:\n",
        "    print(\"FATAL: No features remaining after preprocessing. Check data and column drop logic.\")\n",
        "    exit()\n",
        "\n",
        "# 4. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 5. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame to preserve column names for feature selection steps\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "\n",
        "\n",
        "print(f\"Data split and scaled. X_train shape: {X_train_scaled_df.shape}, X_test shape: {X_test_scaled_df.shape}\")\n",
        "\n",
        "# Store results\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_apz9u6OP_UC",
        "outputId": "dd001f9d-f154-4df5-ae08-5be4689f9d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert column communityName to numeric. It might contain non-numeric strings other than '?'. Dropping it.\n",
            "Missing values handled. Shape of X after imputation: (1994, 143)\n",
            "Data split and scaled. X_train shape: (1395, 143), X_test shape: (599, 143)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to evaluate model\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    print(f\"\\n--- {model_name} ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    # print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
        "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}"
      ],
      "metadata": {
        "id": "Rk6JmlXbP_a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario 1 - Using original dataset with all available features\n",
        "\n",
        "print(\"\\n--- Scenario 1: Model with All Features ---\")\n",
        "# MODIFIED: Changed to LogisticRegression\n",
        "model_all_features = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000) # Increased max_iter for potential convergence issues\n",
        "model_all_features.fit(X_train_scaled_df, y_train)\n",
        "y_pred_all = model_all_features.predict(X_test_scaled_df)\n",
        "results['All Features'] = evaluate_model(y_test, y_pred_all, \"Logistic Regression (All Features)\")\n",
        "\n",
        "# Identify most influential features from the full model\n",
        "# MODIFIED: For Logistic Regression, we look at coefficients\n",
        "if hasattr(model_all_features, 'coef_'):\n",
        "    importances_all = np.abs(model_all_features.coef_[0]) # Absolute values of coefficients for magnitude\n",
        "    feature_names_all = X.columns\n",
        "    feature_importance_df_all = pd.DataFrame({'feature': feature_names_all, 'importance': importances_all})\n",
        "    feature_importance_df_all = feature_importance_df_all.sort_values(by='importance', ascending=False)\n",
        "    print(\"\\nTop 10 features (All Features Model - based on coefficient magnitude):\")\n",
        "    print(feature_importance_df_all.head(10))\n",
        "else:\n",
        "    print(\"Could not retrieve feature importances (coefficients) for the 'All Features' model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzqlRw7jP_7q",
        "outputId": "25275fb1-8450-4e3f-c341-915059f0ae91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scenario 1: Model with All Features ---\n",
            "\n",
            "--- Logistic Regression (All Features) ---\n",
            "Accuracy: 0.9516\n",
            "Precision: 0.9518\n",
            "Recall: 0.9516\n",
            "F1-Score: 0.9516\n",
            "\n",
            "Top 10 features (All Features Model - based on coefficient magnitude):\n",
            "              feature  importance\n",
            "133     assaultPerPop    8.228673\n",
            "131       robbbPerPop    3.351383\n",
            "129       rapesPerPop    0.852288\n",
            "23        whitePerCap    0.839561\n",
            "31    PctLess9thGrade    0.763414\n",
            "30     PctPopUnderPov    0.598893\n",
            "57      PctImmigRec10    0.578409\n",
            "66   PersPerOccupHous    0.516306\n",
            "132          assaults    0.500687\n",
            "46        PctKids2Par    0.493173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Scenario 2: Feature Selection with Genetic Algorithm (GA) ---\")\n",
        "\n",
        "# GA Parameters\n",
        "N_POPULATION = 30\n",
        "N_GENERATIONS = 20\n",
        "CXPB = 0.6\n",
        "MUTPB = 0.2\n",
        "N_FEATURES = X_train_scaled_df.shape[1]\n",
        "\n",
        "# Define Fitness: We want to maximize F1-score\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, N_FEATURES)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tpXm_keQAAj",
        "outputId": "bccf71d8-5a2e-4805-f72b-7a8bd0343503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scenario 2: Feature Selection with Genetic Algorithm (GA) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function for GA\n",
        "def evalFeatures(individual):\n",
        "    selected_feature_indices = [i for i, bit in enumerate(individual) if bit == 1]\n",
        "    if not selected_feature_indices: #\n",
        "        return 0,\n",
        "\n",
        "    # Select features based on the individual\n",
        "    X_train_subset = X_train_scaled_df.iloc[:, selected_feature_indices]\n",
        "    X_test_subset = X_test_scaled_df.iloc[:, selected_feature_indices]\n",
        "\n",
        "    model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=500, solver='liblinear')\n",
        "    model.fit(X_train_subset, y_train)\n",
        "    y_pred = model.predict(X_test_subset)\n",
        "    return f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "\n",
        "toolbox.register(\"evaluate\", evalFeatures)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
      ],
      "metadata": {
        "id": "z_9S72XHQACr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run GA\n",
        "print(f\"Running GA with {N_POPULATION} individuals for {N_GENERATIONS} generations...\")\n",
        "population = toolbox.population(n=N_POPULATION)\n",
        "# To track best fitness over generations\n",
        "logbook = tools.Logbook()\n",
        "logbook.header = \"gen\", \"evals\", \"avg\", \"min\", \"max\"\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "\n",
        "for gen in range(N_GENERATIONS):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=CXPB, mutpb=MUTPB)\n",
        "    fits = toolbox.map(toolbox.evaluate, offspring)\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record = stats.compile(population)\n",
        "    logbook.record(gen=gen, evals=len(offspring), **record)\n",
        "    print(logbook.stream)\n",
        "\n",
        "\n",
        "best_individual_ga = tools.selBest(population, k=1)[0]\n",
        "selected_features_ga_indices = [i for i, bit in enumerate(best_individual_ga) if bit == 1]\n",
        "\n",
        "if not selected_features_ga_indices:\n",
        "    print(\"GA selected no features. This can happen. Using all features as a fallback for this scenario.\")\n",
        "    X_train_ga_selected = X_train_scaled_df\n",
        "    X_test_ga_selected = X_test_scaled_df\n",
        "    selected_feature_names_ga = X.columns.tolist()\n",
        "else:\n",
        "    selected_feature_names_ga = X.columns[selected_features_ga_indices].tolist()\n",
        "    X_train_ga_selected = X_train_scaled_df.iloc[:, selected_features_ga_indices]\n",
        "    X_test_ga_selected = X_test_scaled_df.iloc[:, selected_features_ga_indices]\n",
        "\n",
        "print(f\"\\nGA selected {len(selected_feature_names_ga)} features: {selected_feature_names_ga[:10]}...\") # Print first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNIUeJbGQULC",
        "outputId": "dcb596c1-0010-4d86-e3fb-68a89521fc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running GA with 30 individuals for 20 generations...\n",
            "gen\tevals\tavg     \tmin     \tmax     \n",
            "0  \t30   \t0.925892\t0.856318\t0.973286\n",
            "1  \t30   \t0.96254 \t0.941548\t0.973281\n",
            "2  \t30   \t0.96783 \t0.949906\t0.973281\n",
            "3  \t30   \t0.969668\t0.964929\t0.971615\n",
            "4  \t30   \t0.970447\t0.966601\t0.973286\n",
            "5  \t30   \t0.971227\t0.966609\t0.973286\n",
            "6  \t30   \t0.972339\t0.969944\t0.978296\n",
            "7  \t30   \t0.972506\t0.969946\t0.973286\n",
            "8  \t30   \t0.97323 \t0.971615\t0.974956\n",
            "9  \t30   \t0.973843\t0.973286\t0.974956\n",
            "10 \t30   \t0.974566\t0.973286\t0.976625\n",
            "11 \t30   \t0.975512\t0.973286\t0.978294\n",
            "12 \t30   \t0.976625\t0.974956\t0.978294\n",
            "13 \t30   \t0.977404\t0.973286\t0.978294\n",
            "14 \t30   \t0.97796 \t0.976625\t0.978294\n",
            "15 \t30   \t0.978238\t0.976625\t0.978294\n",
            "16 \t30   \t0.978294\t0.978294\t0.978294\n",
            "17 \t30   \t0.978127\t0.973281\t0.978294\n",
            "18 \t30   \t0.978182\t0.974952\t0.978294\n",
            "19 \t30   \t0.978182\t0.974954\t0.978294\n",
            "\n",
            "GA selected 66 features: ['racepctblack', 'racePctHisp', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'medIncome', 'whitePerCap', 'blackPerCap', 'OtherPerCap']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with GA selected features\n",
        "\n",
        "model_ga = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
        "model_ga.fit(X_train_ga_selected, y_train)\n",
        "y_pred_ga = model_ga.predict(X_test_ga_selected)\n",
        "results['GA Selected'] = evaluate_model(y_test, y_pred_ga, \"Logistic Regression (GA Selected Features)\")\n",
        "\n",
        "\n",
        "if len(selected_feature_names_ga) > 0 and not X_train_ga_selected.empty and hasattr(model_ga, 'coef_') :\n",
        "    importances_ga = np.abs(model_ga.coef_[0])\n",
        "    feature_importance_df_ga = pd.DataFrame({'feature': selected_feature_names_ga, 'importance': importances_ga})\n",
        "    feature_importance_df_ga = feature_importance_df_ga.sort_values(by='importance', ascending=False)\n",
        "    print(\"\\nTop 10 features (GA Selected Model - based on coefficient magnitude):\")\n",
        "    print(feature_importance_df_ga.head(10))\n",
        "else:\n",
        "    print(\"No features selected by GA, features dataframe is empty, or could not retrieve coefficients, skipping importance.\")\n",
        "\n",
        "if \"FitnessMax\" in dir(creator):\n",
        "    del creator.FitnessMax\n",
        "if \"Individual\" in dir(creator):\n",
        "    del creator.Individual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKgLP3ZwQUSy",
        "outputId": "be61c5c9-9ff6-48c5-b9cd-f8216998d070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression (GA Selected Features) ---\n",
            "Accuracy: 0.9766\n",
            "Precision: 0.9768\n",
            "Recall: 0.9766\n",
            "F1-Score: 0.9766\n",
            "\n",
            "Top 10 features (GA Selected Model - based on coefficient magnitude):\n",
            "             feature  importance\n",
            "59     assaultPerPop    8.480988\n",
            "57       robbbPerPop    3.727144\n",
            "56       rapesPerPop    0.833838\n",
            "65     nonViolPerPop    0.792134\n",
            "7        whitePerCap    0.584400\n",
            "58          assaults    0.556310\n",
            "20          NumImmig    0.516749\n",
            "23     PctImmigRec10    0.487112\n",
            "5          numbUrban    0.433784\n",
            "27  PersPerOccupHous    0.418106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Scenario 3: Feature Selection with Particle Swarm Optimization (PSO) ---\")\n",
        "\n",
        "# PSO Parameters\n",
        "N_PARTICLES = 30\n",
        "N_ITERATIONS = 20\n",
        "\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'k': N_PARTICLES // 2, 'p': 2}\n",
        "\n",
        "def pso_fitness_func(swarm_particle_matrix):\n",
        "    costs = []\n",
        "    for particle_idx in range(swarm_particle_matrix.shape[0]):\n",
        "        particle = swarm_particle_matrix[particle_idx, :]\n",
        "        selected_feature_indices = np.where(particle == 1)[0]\n",
        "\n",
        "        if len(selected_feature_indices) == 0:\n",
        "            costs.append(1.0)\n",
        "            continue\n",
        "\n",
        "        X_train_subset = X_train_scaled_df.iloc[:, selected_feature_indices]\n",
        "        X_test_subset = X_test_scaled_df.iloc[:, selected_feature_indices]\n",
        "\n",
        "        model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=500, solver='liblinear')\n",
        "        model.fit(X_train_subset, y_train)\n",
        "        y_pred = model.predict(X_test_subset)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        costs.append(1.0 - f1)\n",
        "    return np.array(costs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_h4SzzlQUXK",
        "outputId": "04b0beff-6eba-48d1-bdde-04297ae4cafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scenario 3: Feature Selection with Particle Swarm Optimization (PSO) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = ps.discrete.BinaryPSO(n_particles=N_PARTICLES, dimensions=N_FEATURES, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "print(f\"Running PSO with {N_PARTICLES} particles for {N_ITERATIONS} iterations...\")\n",
        "cost, best_pos_pso = optimizer.optimize(pso_fitness_func, iters=N_ITERATIONS, verbose=True)\n",
        "\n",
        "selected_features_pso_indices = np.where(best_pos_pso == 1)[0]\n",
        "\n",
        "if len(selected_features_pso_indices) == 0:\n",
        "    print(\"PSO selected no features. Using all features as a fallback.\")\n",
        "    X_train_pso_selected = X_train_scaled_df\n",
        "    X_test_pso_selected = X_test_scaled_df\n",
        "    selected_feature_names_pso = X.columns.tolist()\n",
        "else:\n",
        "    selected_feature_names_pso = X.columns[selected_features_pso_indices].tolist()\n",
        "    X_train_pso_selected = X_train_scaled_df.iloc[:, selected_features_pso_indices]\n",
        "    X_test_pso_selected = X_test_scaled_df.iloc[:, selected_features_pso_indices]\n",
        "\n",
        "print(f\"\\nPSO selected {len(selected_feature_names_pso)} features: {selected_feature_names_pso[:10]}...\")\n",
        "\n",
        "model_pso = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
        "model_pso.fit(X_train_pso_selected, y_train)\n",
        "y_pred_pso = model_pso.predict(X_test_pso_selected)\n",
        "results['PSO Selected'] = evaluate_model(y_test, y_pred_pso, \"Logistic Regression (PSO Selected Features)\")\n",
        "\n",
        "\n",
        "if len(selected_feature_names_pso) > 0 and not X_train_pso_selected.empty and hasattr(model_pso, 'coef_'):\n",
        "    importances_pso = np.abs(model_pso.coef_[0])\n",
        "    feature_importance_df_pso = pd.DataFrame({'feature': selected_feature_names_pso, 'importance': importances_pso})\n",
        "    feature_importance_df_pso = feature_importance_df_pso.sort_values(by='importance', ascending=False)\n",
        "    print(\"\\nTop 10 features (PSO Selected Model - based on coefficient magnitude):\")\n",
        "    print(feature_importance_df_pso.head(10))\n",
        "else:\n",
        "    print(\"No features selected by PSO, features dataframe is empty, or could not retrieve coefficients, skipping importance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEslAgf6QbMS",
        "outputId": "5345751c-3615-4f59-cb88-44c3098e4387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-15 23:25:02,921 - pyswarms.discrete.binary - INFO - Optimize for 20 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9, 'k': 15, 'p': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running PSO with 30 particles for 20 iterations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.discrete.binary: 100%|██████████|20/20, best_cost=0.0217\n",
            "2025-05-15 23:25:38,861 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.021706225946293345, best pos: [1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0\n",
            " 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PSO selected 79 features: ['countyCode', 'communityCode', 'population', 'racepctblack', 'racePctAsian', 'racePctHisp', 'agePct16t24', 'agePct65up', 'pctUrban', 'medIncome']...\n",
            "\n",
            "--- Logistic Regression (PSO Selected Features) ---\n",
            "Accuracy: 0.9783\n",
            "Precision: 0.9786\n",
            "Recall: 0.9783\n",
            "F1-Score: 0.9783\n",
            "\n",
            "Top 10 features (PSO Selected Model - based on coefficient magnitude):\n",
            "             feature  importance\n",
            "77     assaultPerPop    8.405563\n",
            "75       robbbPerPop    4.068743\n",
            "73       rapesPerPop    0.834982\n",
            "15       whitePerCap    0.833348\n",
            "33     PctImmigRec10    0.593458\n",
            "39  PersPerOccupHous    0.576119\n",
            "76          assaults    0.525409\n",
            "29          NumImmig    0.480642\n",
            "11        pctWInvInc    0.388063\n",
            "35      PctRecImmig5    0.355091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize and Compare Performance\n",
        "\n",
        "print(\"\\n--- Performance Summary ---\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df[['accuracy', 'precision', 'recall', 'f1']]\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "# Bar chart for comparison\n",
        "results_df.plot(kind='bar', figsize=(12, 7))\n",
        "plt.title('Model Performance Comparison (Logistic Regression)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Metric')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('performance_comparison_chart_logistic_regression.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "0fgK575XQbOp",
        "outputId": "2b2098e8-08fe-48a1-9939-2a0228760397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performance Summary ---\n",
            "              accuracy  precision    recall        f1\n",
            "All Features  0.951586   0.951831  0.951586  0.951578\n",
            "GA Selected   0.976628   0.976818  0.976628  0.976625\n",
            "PSO Selected  0.978297   0.978558  0.978297  0.978294\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Project Documentation Placeholders ---\")\n",
        "# MODIFIED: Updated for Logistic Regression\n",
        "print(\"\\n1. ML Algorithm (Logistic Regression):\")\n",
        "print(\"   - Flowchart: [Conceptual: Data (Features X, Target y)] -> [Initialize Weights (w) and Bias (b)] -> \")\n",
        "print(\"                [For each epoch OR until convergence: \")\n",
        "print(\"                  [Calculate Linear Combination (z = wX + b)] -> \")\n",
        "print(\"                  [Apply Sigmoid Function (p = 1 / (1 + exp(-z)))] -> \")\n",
        "print(\"                  [Calculate Loss (e.g., Log Loss/Cross-Entropy)] -> \")\n",
        "print(\"                  [Calculate Gradients of Loss w.r.t. w and b] -> \")\n",
        "print(\"                  [Update Weights and Bias using Gradient Descent (w = w - lr*grad_w, b = b - lr*grad_b)] \")\n",
        "print(\"                ] -> [Trained Model (Optimized w, b)] -> [Prediction on New Data]\")\n",
        "print(\"   - Pseudocode:\")\n",
        "print(\"     Algorithm LogisticRegressionTrain(TrainingSet D(X,y), LearningRate lr, Epochs E):\")\n",
        "print(\"       Initialize weights w (vector), bias b (scalar) (e.g., to zeros or small random values)\")\n",
        "print(\"       For epoch = 1 to E:\")\n",
        "print(\"         For each training example (x_i, y_i) in D (or use batch/mini-batch):\")\n",
        "print(\"           z_i = dot_product(w, x_i) + b\")\n",
        "print(\"           p_i = sigmoid(z_i)  // sigmoid(z) = 1 / (1 + exp(-z))\")\n",
        "print(\"           // Calculate gradient for log loss: L = -[y_i * log(p_i) + (1 - y_i) * log(1 - p_i)]\")\n",
        "print(\"           gradient_wrt_z = p_i - y_i\") # Gradient of log loss w.r.t z\n",
        "print(\"           gradient_w = gradient_wrt_z * x_i\")\n",
        "print(\"           gradient_b = gradient_wrt_z\")\n",
        "print(\"           // Update weights and bias\")\n",
        "print(\"           w = w - lr * gradient_w\")\n",
        "print(\"           b = b - lr * gradient_b\")\n",
        "print(\"       Return w, b\")\n",
        "print(\"\")\n",
        "print(\"     To predict for instance x_new with trained w, b:\")\n",
        "print(\"       z_new = dot_product(w, x_new) + b\")\n",
        "print(\"       p_new = sigmoid(z_new)\")\n",
        "print(\"       Return 1 if p_new >= 0.5 else 0 (for binary classification)\")\n",
        "\n",
        "\n",
        "print(\"\\n2. GA Optimization Algorithm Process:\")\n",
        "print(\"   - Flowchart: [Conceptual: Initialize Population -> Evaluate Fitness -> Selection -> Crossover -> Mutation -> New Population -> Repeat until termination]\")\n",
        "print(\"   - Pseudocode (for feature selection):\")\n",
        "print(\"     Algorithm GeneticAlgorithmFeatureSelection(Features, Target, PopSize, Generations):\")\n",
        "print(\"       Initialize Population P with random binary strings (individuals, representing feature subsets)\")\n",
        "print(\"       For g = 1 to Generations:\")\n",
        "print(\"         For each individual I in P:\")\n",
        "print(\"           Fitness(I) = EvaluateMLModel(Features_selected_by_I, Target) // e.g., F1-score of Logistic Regression\")\n",
        "print(\"         P_selected = SelectParents(P, Fitness_values) // e.g., Tournament, Roulette Wheel\")\n",
        "print(\"         P_offspring = Crossover(P_selected) // e.g., One-point, Two-point\")\n",
        "print(\"         P_mutated = Mutate(P_offspring) // e.g., Bit-flip\")\n",
        "print(\"         P = P_mutated (or combine with P_selected for elitism)\")\n",
        "print(\"       Return BestIndividual(P) // Individual with highest fitness\")\n",
        "\n",
        "print(\"\\n3. PSO Optimization Algorithm Process:\")\n",
        "print(\"   - Flowchart: [Conceptual: Initialize Particles (positions, velocities) -> Evaluate Fitness -> Update Personal Best & Global Best -> Update Velocities -> Update Positions -> Repeat until termination]\")\n",
        "print(\"   - Pseudocode (for feature selection):\")\n",
        "print(\"     Algorithm PSOFeatureSelection(Features, Target, NumParticles, Iterations):\")\n",
        "print(\"       Initialize Particles (random binary positions for feature subsets, random velocities)\")\n",
        "print(\"       Initialize pBest_positions = current_positions, pBest_fitness = fitness of current_positions\")\n",
        "print(\"       Initialize gBest_position = best_among_pBests, gBest_fitness = best_among_pBest_fitness\")\n",
        "print(\"       For iter = 1 to Iterations:\")\n",
        "print(\"         For each particle i:\")\n",
        "print(\"           CurrentFitness_i = EvaluateMLModel(Features_selected_by_particle_i_position, Target) // e.g., F1-score of Logistic Regression\")\n",
        "print(\"           If CurrentFitness_i is better than pBest_fitness_i:\")\n",
        "print(\"             pBest_position_i = particle_i_position\")\n",
        "print(\"             pBest_fitness_i = CurrentFitness_i\")\n",
        "print(\"           If CurrentFitness_i is better than gBest_fitness:\")\n",
        "print(\"             gBest_position = particle_i_position\")\n",
        "print(\"             gBest_fitness = CurrentFitness_i\")\n",
        "print(\"         For each particle i:\")\n",
        "print(\"           Update_velocity(particle_i, pBest_position_i, gBest_position, inertia_w, c1, c2)\")\n",
        "print(\"           Update_position(particle_i) // Apply sigmoid to velocity for binary position update, ensure binary {0,1}\")\n",
        "print(\"       Return gBest_position\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n5. Block diagram of the implemented system:\")\n",
        "# MODIFIED: Updated for Logistic Regression\n",
        "print(\"   [Raw CSV Data] -> [Preprocessing (Handle Missing Values, Impute NaNs, Create Target Variable 'crime_category', Scale Features)] -> \")\n",
        "print(\"     |--> [Scenario 1: Train Logistic Regression with All Scaled Features] --> [Evaluate Model 1 (Metrics: Acc, Prec, Rec, F1)]\")\n",
        "print(\"     |--> [Scenario 2: GA for Feature Selection on Scaled Features] -> [Identify GA-Selected Features] -> [Train Logistic Regression with GA-Selected Scaled Features] --> [Evaluate Model 2 (Metrics)]\")\n",
        "print(\"     |--> [Scenario 3: PSO for Feature Selection on Scaled Features] -> [Identify PSO-Selected Features] -> [Train Logistic Regression with PSO-Selected Scaled Features] --> [Evaluate Model 3 (Metrics)]\")\n",
        "print(\"     --> [Compare Metrics & Visualize Performance (Bar Chart)]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSmTQ35QlMK",
        "outputId": "5e72c996-4992-4375-be3b-56ea76d571dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Project Documentation Placeholders ---\n",
            "\n",
            "1. ML Algorithm (Logistic Regression):\n",
            "   - Flowchart: [Conceptual: Data (Features X, Target y)] -> [Initialize Weights (w) and Bias (b)] -> \n",
            "                [For each epoch OR until convergence: \n",
            "                  [Calculate Linear Combination (z = wX + b)] -> \n",
            "                  [Apply Sigmoid Function (p = 1 / (1 + exp(-z)))] -> \n",
            "                  [Calculate Loss (e.g., Log Loss/Cross-Entropy)] -> \n",
            "                  [Calculate Gradients of Loss w.r.t. w and b] -> \n",
            "                  [Update Weights and Bias using Gradient Descent (w = w - lr*grad_w, b = b - lr*grad_b)] \n",
            "                ] -> [Trained Model (Optimized w, b)] -> [Prediction on New Data]\n",
            "   - Pseudocode:\n",
            "     Algorithm LogisticRegressionTrain(TrainingSet D(X,y), LearningRate lr, Epochs E):\n",
            "       Initialize weights w (vector), bias b (scalar) (e.g., to zeros or small random values)\n",
            "       For epoch = 1 to E:\n",
            "         For each training example (x_i, y_i) in D (or use batch/mini-batch):\n",
            "           z_i = dot_product(w, x_i) + b\n",
            "           p_i = sigmoid(z_i)  // sigmoid(z) = 1 / (1 + exp(-z))\n",
            "           // Calculate gradient for log loss: L = -[y_i * log(p_i) + (1 - y_i) * log(1 - p_i)]\n",
            "           gradient_wrt_z = p_i - y_i\n",
            "           gradient_w = gradient_wrt_z * x_i\n",
            "           gradient_b = gradient_wrt_z\n",
            "           // Update weights and bias\n",
            "           w = w - lr * gradient_w\n",
            "           b = b - lr * gradient_b\n",
            "       Return w, b\n",
            "\n",
            "     To predict for instance x_new with trained w, b:\n",
            "       z_new = dot_product(w, x_new) + b\n",
            "       p_new = sigmoid(z_new)\n",
            "       Return 1 if p_new >= 0.5 else 0 (for binary classification)\n",
            "\n",
            "2. GA Optimization Algorithm Process:\n",
            "   - Flowchart: [Conceptual: Initialize Population -> Evaluate Fitness -> Selection -> Crossover -> Mutation -> New Population -> Repeat until termination]\n",
            "   - Pseudocode (for feature selection):\n",
            "     Algorithm GeneticAlgorithmFeatureSelection(Features, Target, PopSize, Generations):\n",
            "       Initialize Population P with random binary strings (individuals, representing feature subsets)\n",
            "       For g = 1 to Generations:\n",
            "         For each individual I in P:\n",
            "           Fitness(I) = EvaluateMLModel(Features_selected_by_I, Target) // e.g., F1-score of Logistic Regression\n",
            "         P_selected = SelectParents(P, Fitness_values) // e.g., Tournament, Roulette Wheel\n",
            "         P_offspring = Crossover(P_selected) // e.g., One-point, Two-point\n",
            "         P_mutated = Mutate(P_offspring) // e.g., Bit-flip\n",
            "         P = P_mutated (or combine with P_selected for elitism)\n",
            "       Return BestIndividual(P) // Individual with highest fitness\n",
            "\n",
            "3. PSO Optimization Algorithm Process:\n",
            "   - Flowchart: [Conceptual: Initialize Particles (positions, velocities) -> Evaluate Fitness -> Update Personal Best & Global Best -> Update Velocities -> Update Positions -> Repeat until termination]\n",
            "   - Pseudocode (for feature selection):\n",
            "     Algorithm PSOFeatureSelection(Features, Target, NumParticles, Iterations):\n",
            "       Initialize Particles (random binary positions for feature subsets, random velocities)\n",
            "       Initialize pBest_positions = current_positions, pBest_fitness = fitness of current_positions\n",
            "       Initialize gBest_position = best_among_pBests, gBest_fitness = best_among_pBest_fitness\n",
            "       For iter = 1 to Iterations:\n",
            "         For each particle i:\n",
            "           CurrentFitness_i = EvaluateMLModel(Features_selected_by_particle_i_position, Target) // e.g., F1-score of Logistic Regression\n",
            "           If CurrentFitness_i is better than pBest_fitness_i:\n",
            "             pBest_position_i = particle_i_position\n",
            "             pBest_fitness_i = CurrentFitness_i\n",
            "           If CurrentFitness_i is better than gBest_fitness:\n",
            "             gBest_position = particle_i_position\n",
            "             gBest_fitness = CurrentFitness_i\n",
            "         For each particle i:\n",
            "           Update_velocity(particle_i, pBest_position_i, gBest_position, inertia_w, c1, c2)\n",
            "           Update_position(particle_i) // Apply sigmoid to velocity for binary position update, ensure binary {0,1}\n",
            "       Return gBest_position\n",
            "\n",
            "5. Block diagram of the implemented system:\n",
            "   [Raw CSV Data] -> [Preprocessing (Handle Missing Values, Impute NaNs, Create Target Variable 'crime_category', Scale Features)] -> \n",
            "     |--> [Scenario 1: Train Logistic Regression with All Scaled Features] --> [Evaluate Model 1 (Metrics: Acc, Prec, Rec, F1)]\n",
            "     |--> [Scenario 2: GA for Feature Selection on Scaled Features] -> [Identify GA-Selected Features] -> [Train Logistic Regression with GA-Selected Scaled Features] --> [Evaluate Model 2 (Metrics)]\n",
            "     |--> [Scenario 3: PSO for Feature Selection on Scaled Features] -> [Identify PSO-Selected Features] -> [Train Logistic Regression with PSO-Selected Scaled Features] --> [Evaluate Model 3 (Metrics)]\n",
            "     --> [Compare Metrics & Visualize Performance (Bar Chart)]\n"
          ]
        }
      ]
    }
  ]
}